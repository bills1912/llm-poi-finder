# HeyPico Maps LLM - Code Test 2

A local LLM-powered location finder with Google Maps integration. Users can ask the LLM for place recommendations and view locations on an embedded map with directions.

## ğŸ¯ Project Overview

This project implements a conversational AI system that:
- Runs a local LLM (using Ollama) to understand user queries about places
- Integrates with Google Maps API to fetch location data
- Displays interactive maps with markers and directions
- Provides secure API key management and usage limits

## ğŸ“ Project Structure

```
heytico-maps-llm/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI application entry
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration & environment
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py          # Chat/LLM endpoints
â”‚   â”‚   â”‚   â””â”€â”€ maps.py          # Google Maps endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py   # Ollama LLM integration
â”‚   â”‚   â”‚   â””â”€â”€ maps_service.py  # Google Maps service
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ rate_limiter.py  # Rate limiting middleware
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ validators.py    # Input validation
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â””â”€â”€ app.js
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh
â”‚   â””â”€â”€ start.sh
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ SETUP.md
â”‚   â””â”€â”€ ASSUMPTIONS.md
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

1. **Docker & Docker Compose** (recommended)
2. **Python 3.10+** (for local development)
3. **Google Cloud Account** with Maps API enabled
4. **Ollama** installed locally

### Setup Instructions

#### 1. Clone and Navigate
```bash
cd heytico-maps-llm
```

#### 2. Google Cloud Setup
1. Create a new Google Cloud project at https://console.cloud.google.com
2. Enable the following APIs:
   - Maps JavaScript API
   - Places API
   - Directions API
   - Geocoding API
3. Create API credentials (API Key)
4. Set up API key restrictions:
   - HTTP referrers (for frontend)
   - IP addresses (for backend)
5. Set usage quotas to prevent unexpected charges

#### 3. Environment Configuration
```bash
cp backend/.env.example backend/.env
# Edit backend/.env with your API keys
```

#### 4. Install Ollama and Pull Model
```bash
# Install Ollama (Linux)
curl -fsSL https://ollama.com/install.sh | sh

# Pull the LLM model (choose one)
ollama pull llama3.2        # Recommended: Good balance
ollama pull mistral         # Alternative: Fast
ollama pull phi3            # Alternative: Lightweight
```

#### 5. Run with Docker Compose
```bash
docker-compose up --build
```

#### 6. Or Run Locally
```bash
# Backend
cd backend
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000

# Frontend (separate terminal)
python serve_frontend.py
```

### 7. Access the Application
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Documentation: http://localhost:8000/docs

## ğŸ” Security Best Practices

### API Key Protection
- âœ… API keys stored in environment variables, never in code
- âœ… Backend-only API calls (frontend never exposes keys)
- âœ… API key restrictions configured in Google Cloud Console
- âœ… Rate limiting implemented on all endpoints

### Usage Limits
- âœ… Per-user rate limiting (configurable)
- âœ… Daily quota tracking
- âœ… Request validation and sanitization
- âœ… Error handling for quota exceeded

## ğŸ“– API Documentation

See [docs/API.md](docs/API.md) for complete API documentation.

### Key Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/chat` | Send message to LLM, get places |
| GET | `/api/places/search` | Search places by query |
| GET | `/api/places/details/{id}` | Get place details |
| GET | `/api/directions` | Get directions between points |
| GET | `/api/health` | Health check endpoint |

## ğŸ§  LLM Integration

The system uses Ollama to run local LLMs. The LLM is prompted to:
1. Understand user intent (finding places to eat, visit, etc.)
2. Extract relevant search parameters (cuisine, location, etc.)
3. Format responses with place recommendations

### Supported Queries
- "Where can I find good sushi near Times Square?"
- "Best coffee shops in downtown Seattle"
- "Recommend Italian restaurants in Chicago"
- "Find parking near Central Park"

## ğŸ—ºï¸ Google Maps Features

- **Place Search**: Find places by query and location
- **Place Details**: Get address, ratings, hours, photos
- **Embedded Maps**: Interactive map display with markers
- **Directions**: Get routes between locations
- **Street View**: Preview locations (optional)

## ğŸ§ª Testing

```bash
cd backend
pytest tests/ -v
```

## ğŸ“ Assumptions Made

See [docs/ASSUMPTIONS.md](docs/ASSUMPTIONS.md) for detailed assumptions.

Key assumptions:
1. User has access to Google Cloud free tier ($200 credit)
2. Ollama is available for local LLM deployment
3. Modern browser with JavaScript enabled
4. Single-user or limited concurrent users for demo

## ğŸ› ï¸ Technology Stack

- **Backend**: Python 3.10+, FastAPI, Pydantic
- **Frontend**: Vanilla JS, HTML5, CSS3
- **LLM**: Ollama (llama3.2/mistral/phi3)
- **Maps**: Google Maps JavaScript API, Places API
- **Container**: Docker, Docker Compose

## ğŸ“œ License

MIT License - See LICENSE file

## ğŸ‘¤ Author

Created for HeyPico.ai Fullstack Developer Assessment
